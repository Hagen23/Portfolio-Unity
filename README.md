# Unity Portfolio

Some of the project where I have been involved using Unity.

I was a developer lead for a Unity plugin, comissioned by a video-game company called Larva Studios, that was able to detect detect the body, and map it to a rigged model using the Kinect sensor; this served as a MOCAP system within Unity. The plugin also detected the palms of the hands. 

The plugin was used to create two video-games:

For the hand tracking, a modelling game:

<div><a href="https://www.youtube.com/watch?v=4Xquc4MOBY8" target="_blank"><img src="http://img.youtube.com/vi/4Xquc4MOBY8/0.jpg" 
alt="Modelling Game" width="600" height="400" border="10" /></a></div>

and for the MOCAP, a game where you control a car and an airplane with body postures. Several gestures were detected, such as raising the arms, or flexing:

<div><a href="https://www.youtube.com/watch?v=RSJME_Hk8eg" target="_blank"><img src="http://img.youtube.com/vi/RSJME_Hk8eg/0.jpg" 
alt="MOCAP Game" width="600" height="400" border="10" /></a></div>

The project included in this repository contains three scenes where several lighting effects, as well as the post-processing stack, have been implemented. 

The first scene is a simple box with objects, where three light sources are in play. 

<img align="left" src="Images/Basic_lighting.png" width="97.5%"/>


The second is a low-poly valley, with several elements, including a lake. 

<img align="left" src="Images/Lowpoly_forest_3.png" width="49%"/> 
<img align="left" src="Images/Lowpoly_lake.png" width="49%"/> 


The final scene is a Sci-fi landing dock, with more complex lighting.

<img align="left" src="Images/Scifi_overview.png" width="31%"/> 
<img align="left" src="Images/Scifi_desk.png" width="31%"/> 
<img align="left" src="Images/Scifi_ship.png" width="31%"/> 
